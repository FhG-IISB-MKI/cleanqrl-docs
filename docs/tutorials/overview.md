# Overview

In this section we provide a list of tutorials. We show you how to easily and quickly change specific parts of the code in order to enhance the QRL agents and apply them to various custom problems. 


* **[Graph encodings for the Traveling Salesperson Problem (TSP)](https://fhg-iisb-mki.github.io/cleanqrl-docs/tutorials/graph_encoding/)**

    In this tutorial, we will show how to implement the ideas of Andrea Skolik's paper [Equivariant quantum circuits for learning on weighted graphs](https://www.nature.com/articles/s41534-023-00710-y)


* **[Hamiltonian encodings for the Knapsack Problem (KP)](https://fhg-iisb-mki.github.io/cleanqrl-docs/tutorials/hamiltonian_encoding/)**

    In this tutorial, we will show how to use the results from the paper [Hamiltonian-based Quantum Reinforcement Learning for Neural Combinatorial Optimization](https://arxiv.org/abs/2405.07790)


* **[Noise Models: How your algorithm would perform on real quantum hardware](https://fhg-iisb-mki.github.io/cleanqrl-docs/tutorials/noise_models/)**

    In this tutorial we will show how to use the noise models from the paper [Robustness of quantum reinforcement learning under hardware errors](https://link.springer.com/article/10.1140/epjqt/s40507-023-00166-1) to evaluate the performance of your QRL algorithm on real quantum hardware.

* **[Custom Maze Games: Why scaling is an issue](https://fhg-iisb-mki.github.io/cleanqrl-docs/tutorials/custom_maze/)**
    
    In this tutorial we will show how to use the widely used maze games as a benchmark for QRL algorithms. 
     